#  About This Package

This package functions as executor to create, insert, vectorized and search on tidb database. Shortly 
could said this is a database connector to Tidb cloud. 

ğŸš€ How to Run It

ğŸ“¥ Download

```bash
docker pull ghcr.io/hendram/vectorembedgen
```

â–¶ï¸ Start

```bash
docker run -it -d --network=host ghcr.io/hendram/vectorembedgen bash
```

ğŸ” Check Running Container

```bash
docker ps
```

```bash
CONTAINER ID   IMAGE                               NAME                STATUS
123abc456def   ghcr.io/hendram/vectorembedgen      confident_banzai    Up 5 minutes
```

ğŸ“¦ Enter Container

```bash
docker exec -it confident_banzai /bin/bash
```

ğŸƒ Run the Service

```bash
cd /home
source .venv/bin/activate
uvicorn vectorembedgen:app --host 0.0.0.0 --port 8000
```

---

# ğŸ“– **How This Works**

####  This works based on some logic received from chunkgeneratorforaimodel

ğŸ“Œ /embed Endpoint â€“ Embedding and Storage Pipeline

### The /embed API endpoint is responsible for:

ğŸ“ Extracting the searched keyword from incoming document chunks.

ğŸ§¹ Normalizing a table name to store embeddings for that keyword.

ğŸ—„ï¸ Creating or refreshing the external table (if it does not exist or is too old).

âš¡ Enabling TiFlash replication for accelerated vector search queries.

ğŸ§­ Creating a vector index on the embeddings column.

ğŸ“¥ Inserting document chunks and their embeddings into the external table.

ğŸ”„ Updating the keyword status in the keywords table.

ğŸ”¹ Endpoint Definition

---

####  @app.post("/embed")
async def embed(chunks: list[dict] = Body(...)):


Accepts a JSON body containing a list of chunks.

Each chunk contains:

"text" â†’ the content to embed.

"metadata" â†’ details such as url, date, sourcekb, and the searched keyword.

ğŸ”¹ Processing Steps
âœ… Validate Input

Ensures the request contains chunks.

Extracts the searched keyword from the first chunkâ€™s metadata.

If no keyword is provided â†’ âŒ returns an error.

ğŸ§¹ Normalize Keyword

Strips filters like --filetype or -site.

Produces a clean base keyword used to name the external table.

external_table = normalize_table_name_external(base_keyword)


â¡ï¸ Ensures each search term has its own dedicated table for embeddings.

ğŸ§  Encode Embeddings

Converts chunks into embeddings with model.encode().

vecs = model.encode(texts, show_progress_bar=False)

ğŸ—„ï¸ Manage External Table

Connects via SessionLocal.

If table exists but is older than 3 days â†’ drop and recreate.

Else â†’ create fresh.

CREATE TABLE {external_table} (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    chunk_text TEXT NOT NULL,
    embedding VECTOR(384),
    url TEXT,
    retrieved_at TIMESTAMP,
    sourcekb VARCHAR(100)
);

âš¡ Enable TiFlash Replication
ALTER TABLE {external_table} SET TIFLASH REPLICA 1;


â¡ï¸ Waits until TiFlash is ready before proceeding.

ğŸ§­ Create Vector Index
ALTER TABLE {external_table}
ADD VECTOR INDEX embedding_idx ((VEC_COSINE_DISTANCE(embedding)))
USING HNSW;


â¡ï¸ Optimizes nearest-neighbor lookups for similarity search.

ğŸ“¥ Insert Chunks with Embeddings

Inserts:

chunk_text â†’ raw text

embedding â†’ 384-dim vector

url â†’ source URL

retrieved_at â†’ timestamp

sourcekb â†’ knowledge base type

â¡ï¸ Duplicate entries â†’ update existing rows.

ğŸ”„ Update Keywords Table
UPDATE keywords
SET status = 'completed', last_seen = CURRENT_TIMESTAMP
WHERE keyword = :kw;

ğŸ”¹ Response
{
  "status": "ok",
  "inserted_count": 25,
  "external_table": "python_programming",
  "keyword_status": "completed"
}


inserted_count â†’ number of chunks stored.

external_table â†’ name of created table.

keyword_status â†’ processing state.

ğŸ“Œ /insertsearchtodb Endpoint â€“ Keyword Tracking

This endpoint manages the keywords table.

ğŸ“ Tracks every searched keyword.

âš™ï¸ Stores its status (pending / completed).

ğŸ”„ Updates usage statistics.

ğŸ”¹ Endpoint Definition
@app.post("/insertsearchtodb")
async def insert_search_to_db(topic: dict = Body(...)):


Accepts:

{ "searched": "python tutorial --filetype:pdf" }

ğŸ”¹ Processing Steps
âœ… Validate Input

If "searched" missing â†’

{ "answer": "no", "reason": "No searched text provided" }

ğŸ—„ï¸ Ensure keywords Table Exists
CREATE TABLE IF NOT EXISTS keywords (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    keyword VARCHAR(255) UNIQUE,
    status ENUM('pending','completed') DEFAULT 'pending',
    last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    searches INT DEFAULT 1
);

ğŸ” Check if Keyword Exists
SELECT keyword, status, searches
FROM keywords
WHERE keyword = :kw;


If new â†’ insert with pending.

Else â†’ increment counter + update timestamp.

ğŸ”„ Return Based on Status

If status = completed â†’

{ "answer": "yes", "status": "completed" }


If status = pending â†’

{ "answer": "no", "status": "pending" }

ğŸ“Œ /searchvectordb Endpoint â€“ Semantic Multiple-Choice Search

This endpoint performs semantic similarity search to select the best multiple-choice answer.

Takes: question + options.

Searches embeddings.

Computes similarity.

âœ… Picks the best-scoring option.

ğŸ”¹ Endpoint Definition
@app.post("/searchvectordb")
async def searchvectordb(payload: dict = Body(...)):


Input:

{
  "query": {
    "question": {
      "question": "Which language is used in FastAPI?",
      "options": ["Python", "Java", "Go"],
      "metadata": { "searched": "fastapi tutorial" }
    }
  }
}

ğŸ”¹ Processing Steps
âœ… Parse and Validate Input

Extracts:

question

options

metadata.searched

ğŸ§¹ Normalize Keyword

From metadata.searched.

Used to decide which tables to query.

â³ Apply Time Cutoffs

Internal KB â†’ 365 days.

External KB â†’ 90 days.

ğŸ§  Encode Question + Option Pair
query_text = f"{question} {option}"
vec = model.encode([query_text])[0]

ğŸŒ Search External Knowledgebase

Table: <base_keyword>_external.

If exists â†’ select rows (fresh within 90 days).

Compute cosine similarity.

ğŸ  Search Internal Knowledgebase

Table: <base_keyword>_internal.

If exists â†’ select rows (fresh within 365 days).

Compute cosine similarity.

ğŸ“Š Pick Best Chunk per Option

For each option â†’ best scoring chunk.

If none â†’ score = 0.

âœ… Pick Best Answer

Select option with highest similarity score.

ğŸ”¹ Response
{
  "status": "ok",
  "question": "Which language is used in FastAPI?",
  "options": ["Python", "Java", "Go"],
  "bestAnswer": "Python",
  "metadata": { "searched": "fastapi tutorial" }
}


If error â†’

{ "status": "error", "message": "" }

ğŸ”„ Workflow Summary

/insertsearchtodb â†’ track keyword (pending/completed).

/embed â†’ process + store embeddings (mark completed).

/searchvectordb â†’ retrieve best multiple-choice answer. or direct to here if /insertsearchtodb checked table already completed

â¡ï¸ Together, they form a full ingestion + retrieval pipeline.
